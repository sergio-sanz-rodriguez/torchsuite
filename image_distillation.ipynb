{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e3e0ca",
   "metadata": {},
   "source": [
    "# 1. Introuction\n",
    "\n",
    " This notebook outlines the creation, compilation, and training of a Swin Tranformer network to classify 101 types of food. To this end, the **distillation technique** is applied to learn from a larger, pre-trained transformer model, especifically, a ViT-Base/16-384 transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555499",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ConstantLR, SequentialLR, CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom libraries\n",
    "from utils.classification_utils import set_seeds, display_random_images\n",
    "from engines.classification import ClassificationEngine, Common\n",
    "from dataloaders.image_dataloaders import create_distillation_dataloaders, create_dataloaders\n",
    "from engines.loss_functions import DistillationLoss\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.autograd.graph\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"onnxscript.converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403c078",
   "metadata": {},
   "source": [
    "# 3. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94336973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "AMOUNT_TO_GET = 1.0\n",
    "SEED = 42\n",
    "\n",
    "# Define target data directory\n",
    "TARGET_DIR_NAME = f\"data/food-101_{str(int(AMOUNT_TO_GET*100))}_percent\"\n",
    "\n",
    "# Setup training and test directories\n",
    "TARGET_DIR = Path(TARGET_DIR_NAME)\n",
    "TRAIN_DIR = TARGET_DIR / \"train\"\n",
    "TEST_DIR = TARGET_DIR / \"test\"\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target model directory\n",
    "MODEL_DIR = Path(\"outputs\")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "IMPORT_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18615cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPORT_DATASET:\n",
    "    # Download dataset from Hugging Face\n",
    "    ds = load_dataset(\"ethz/food101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc78c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPORT_DATASET:\n",
    "    # Get class names\n",
    "    class_names = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "    # Function to save images into appropriate directories\n",
    "    def save_images(split, target_dir):\n",
    "        for example in tqdm(ds[split], desc=f\"Saving {split} images\"):\n",
    "            image = example[\"image\"]\n",
    "            label = example[\"label\"]\n",
    "            class_name = class_names[label]\n",
    "\n",
    "            # Define class directory\n",
    "            class_dir = target_dir / class_name\n",
    "            class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Save image\n",
    "            img_path = class_dir / f\"{len(list(class_dir.iterdir()))}.jpg\"\n",
    "            image.save(img_path)\n",
    "\n",
    "    # Save training and test images\n",
    "    save_images(\"train\", TRAIN_DIR)\n",
    "    save_images(\"validation\", TEST_DIR)\n",
    "\n",
    "    print(\"Dataset has been saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279df5f",
   "metadata": {},
   "source": [
    "# 4. Specifying Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate cuda benchmark\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "#if device == \"cuda\":\n",
    "#    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350701ec-c5f9-4809-884c-69a5dcf97ceb",
   "metadata": {},
   "source": [
    "# 5. Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "manual_transforms = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.RandomCrop((256, 256)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=manual_transforms)\n",
    "display_random_images(train_data,\n",
    "                      n=25,\n",
    "                      classes=train_data.classes,\n",
    "                      rows=5,\n",
    "                      cols=5,\n",
    "                      display_shape=False,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c28c3",
   "metadata": {},
   "source": [
    "# 6. Creating Teacher and Student - 101 Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae602ca0",
   "metadata": {},
   "source": [
    "To download a teacher model example, click [here](https://drive.google.com/file/d/1uHQ9WotGHh6suSMvkyO0vLj1O8XlJ_yE/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc544d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transformations\n",
    "IMG_SIZE_TCH = 384\n",
    "IMG_SIZE_STD = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "transform_train_tch = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((IMG_SIZE_TCH)),\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_tch = v2.Compose([    \n",
    "    v2.Resize((IMG_SIZE_TCH)),\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_train_std = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((260)),\n",
    "    v2.RandomCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_std = v2.Compose([    \n",
    "    v2.Resize((260)),\n",
    "    v2.CenterCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = create_distillation_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    transform_student_train=transform_train_std,\n",
    "    transform_teacher_train=transform_train_tch,\n",
    "    transform_student_test=transform_test_std,\n",
    "    transform_teacher_test=transform_test_tch,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'test':  test_dataloader\n",
    "}\n",
    "\n",
    "# Load ViT-Base/16-384. Run classification_example.ipynb to genereate the teacher model. \n",
    "model_tch_type=\"teacher_model\"\n",
    "model_tch_name = model_tch_type + \".pth\"\n",
    "\n",
    "# Instantiate the model\n",
    "NUM_CLASSES = len(class_names)\n",
    "model_tch = torchvision.models.vit_b_16(image_size=IMG_SIZE_TCH).to(device)\n",
    "model_tch.heads = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "model_tch = torch.compile(model_tch, backend=\"aot_eager\")\n",
    "\n",
    "# Load the trained weights\n",
    "model_tch = Common().load_model(\n",
    "    model=model_tch,\n",
    "    target_dir=MODEL_DIR,\n",
    "    model_name=model_tch_name)\n",
    "\n",
    "# Copy weights from torchvision.models\n",
    "set_seeds(SEED)\n",
    "\n",
    "# Instantiate the model: Swin Transformer V2-Tiny\n",
    "model_std = torchvision.models.swin_v2_t(weights=torchvision.models.Swin_V2_T_Weights.DEFAULT)\n",
    "model_std.head = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "\n",
    "# Unfreeze the base parameters\n",
    "for parameter in model_std.parameters():\n",
    "    parameter.requires_grad = True\n",
    "\n",
    "# Print summary\n",
    "#summary(model_tch,\n",
    "#        input_size=(BATCH_SIZE,3,IMG_SIZE_TCH, IMG_SIZE_TCH),\n",
    "#        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#        col_width=20,\n",
    "#        row_settings=[\"var_names\"])\n",
    "\n",
    "# Print summary\n",
    "summary(model_std,\n",
    "        input_size=(BATCH_SIZE,3,IMG_SIZE_STD, IMG_SIZE_STD),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f72f2f",
   "metadata": {},
   "source": [
    "# 7. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_std_type=\"student_model\"\n",
    "model_std_name = model_std_type + \".pth\"\n",
    "\n",
    "# Epochs and learning rate\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "MIN_LR = 1e-6\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model_std.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Create loss function\n",
    "loss_fn = DistillationLoss(alpha=0.1, temperature=2, label_smoothing=0.1)\n",
    "\n",
    "# Initialize the scheduler\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=20, eta_min=MIN_LR) # 1-20:  LR = LR -> MIN_LR (cosine)\n",
    "fixed = ConstantLR(optimizer, factor=MIN_LR/LR, total_iters=10) # 20-30: LR = MIN_LR\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[cosine, fixed],\n",
    "    milestones=[20] \n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the engine\n",
    "engine = ClassificationEngine(\n",
    "    model=model_std,                                # Model to be trained\n",
    "    model_teacher=model_tch,                        # Teacher model if knowledge distillation training is enabled (use_distillation=True)\n",
    "    use_distillation=True,                          # Whether training uses knowledge distillation, then model_teacher is required    \n",
    "    optimizer=optimizer,                            # Optimizer\n",
    "    loss_fn=loss_fn,                                # Loss function\n",
    "    scheduler=scheduler,                            # Scheduler\n",
    "    theme='dark',                                   # Theme\n",
    "    device=device                                   # Target device\n",
    "    )\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                           # Directory where the model will be saved\n",
    "    model_name=model_std_name,                      # Name of the student model    \n",
    "    resume=True,                                    # Resume training from the last saved checkpoint\n",
    "    dataloaders=dataloaders,                        # Dictionary with the dataloaders\n",
    "    save_best_model=[\"last\", \"loss\", \"acc\", \"f1\"],  # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,               # Do not keep the models stored in memory for the sake of training time and memory efficiency    \n",
    "    apply_validation=True,                          # Enable validation step\n",
    "    augmentation_strategy=\"always\",                 # Augmentation strategy\n",
    "    recall_threshold=0.995,                         # False   positive rate at recall_threshold recall\n",
    "    recall_threshold_pauc=0.95,                     # Partial AUC score above recall_threshold_pauc recall\n",
    "    epochs=EPOCHS,                                  # Total number of epochs\n",
    "    amp=True,                                       # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                          # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                               # Disable debug mode    \n",
    "    accumulation_steps=4,                           # Accumulation steps 4: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf75d2",
   "metadata": {},
   "source": [
    "## 7.1. (Optional) Retraining the Last Best-performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transformations\n",
    "IMG_SIZE_TCH = 384\n",
    "IMG_SIZE_STD = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "transform_train_tch = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((IMG_SIZE_TCH)),\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_tch = v2.Compose([    \n",
    "    v2.Resize((IMG_SIZE_TCH)),\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_train_std = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((256)),\n",
    "    v2.RandomCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_std = v2.Compose([    \n",
    "    v2.Resize((256)),\n",
    "    v2.CenterCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = create_distillation_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    transform_student_train=transform_train_std,\n",
    "    transform_teacher_train=transform_train_tch,\n",
    "    transform_student_test=transform_test_std,\n",
    "    transform_teacher_test=transform_test_tch,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'test':  test_dataloader\n",
    "}\n",
    "\n",
    "# Load ViT-Base/16-384. Run classification_example.ipynb to genereate the teacher model. \n",
    "model_tch_type=\"teacher_model\"\n",
    "model_tch_name = model_tch_type + \".pth\"\n",
    "\n",
    "# Instantiate the teacher model\n",
    "NUM_CLASSES = len(class_names)\n",
    "model_tch = torchvision.models.vit_b_16(image_size=IMG_SIZE_TCH).to(device)\n",
    "model_tch.heads = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "model_tch = torch.compile(model_tch, backend=\"aot_eager\")\n",
    "\n",
    "# Load the trained weights\n",
    "model_tch = Common().load_model(\n",
    "    model=model_tch,\n",
    "    target_dir=MODEL_DIR,\n",
    "    model_name=model_tch_name)\n",
    "\n",
    "# Instantiate the base student model: Swin Transformer V2-Tiny\n",
    "model_std = torchvision.models.swin_v2_t(weights=torchvision.models.Swin_V2_T_Weights.DEFAULT)\n",
    "model_std.head = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "\n",
    "# Unfreeze the base parameters\n",
    "for parameter in model_std.parameters():\n",
    "    parameter.requires_grad = True\n",
    "\n",
    "# Load the trained weights\n",
    "model_std = Common().load_model(\n",
    "    model=model_std,\n",
    "    target_dir=MODEL_DIR,\n",
    "    model_name=\"student_model2_acc_epoch25.pth\") # Modify the file name if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model_std_type=\"student_model_retrained\"\n",
    "model_std_name = model_std_type + \".pth\"\n",
    "\n",
    "# Epochs and learning rate\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "MIN_LR = 1e-6\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model_std.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Create loss function\n",
    "loss_fn = DistillationLoss(alpha=0.1, temperature=2, label_smoothing=0.1)\n",
    "\n",
    "# Initialize the scheduler\n",
    "#scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, last_epoch=-1, eta_min=MIN_LR)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=20, eta_min=MIN_LR) # 1-20:  LR = LR -> MIN_LR (cosine)\n",
    "fixed = ConstantLR(optimizer, factor=MIN_LR/LR, total_iters=10) # 20-30: LR = MIN_LR\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[cosine, fixed],\n",
    "    milestones=[20] \n",
    ")\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the engine\n",
    "engine = ClassificationEngine(\n",
    "    model=model_std,                                # Model to be trained\n",
    "    model_teacher=model_tch,                        # Teacher model if knowledge distillation training is enabled (use_distillation=True)\n",
    "    use_distillation=True,                          # Whether training uses knowledge distillation, then model_teacher is required    \n",
    "    optimizer=optimizer,                            # Optimizer\n",
    "    loss_fn=loss_fn,                                # Loss function\n",
    "    scheduler=scheduler,                            # Scheduler\n",
    "    color_map={\"train\": 'blue', \"test\": \"orange\"},  # Color map\n",
    "    theme='dark',                                   # Color theme\n",
    "    device=device                                   # Target device\n",
    "    )\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                           # Directory where the model will be saved\n",
    "    model_name=model_std_name,                      # Name of the student model    \n",
    "    resume=False,                                   # Resume training from the last saved checkpoint\n",
    "    dataloaders=dataloaders,                        # Dictionary with the dataloaders\n",
    "    save_best_model=[\"last\", \"loss\", \"acc\", \"f1\"],  # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,               # Do not keep the models stored in memory for the sake of training time and memory efficiency    \n",
    "    apply_validation=True,                          # Enable validation step\n",
    "    augmentation_strategy=\"always\",                 # Augmentation strategy\n",
    "    recall_threshold=0.995,                         # False   positive rate at recall_threshold recall\n",
    "    recall_threshold_pauc=0.95,                     # Partial AUC score above recall_threshold_pauc recall\n",
    "    epochs=EPOCHS,                                  # Total number of epochs\n",
    "    amp=True,                                       # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                          # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                               # Disable debug mode    \n",
    "    accumulation_steps=2,                           # Accumulation steps 4: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910ae33",
   "metadata": {},
   "source": [
    "# 8. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9dc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for the student\n",
    "_, test_dataloader, _ = create_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    train_transform=transform_train_std,\n",
    "    test_transform=transform_test_std,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Make predictions with the student\n",
    "model_std = torchvision.models.swin_v2_t(weights=torchvision.models.Swin_V2_T_Weights.DEFAULT)\n",
    "model_std.head = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "preds_std = ClassificationEngine(\n",
    "    model=model_std,    \n",
    "    device=device).load(\n",
    "        target_dir=MODEL_DIR,\n",
    "        model_name=\"student_model.pth\" # Only parameters, not the enginer model. Modify the file name if necessary.\n",
    "    ).predict(\n",
    "        dataloader=test_dataloader,\n",
    "        output_type=\"argmax\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for the teacher\n",
    "_, test_dataloader, _ = create_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    train_transform=transform_train_tch,\n",
    "    test_transform=transform_test_tch,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Make predictions with the student\n",
    "model_tch = torchvision.models.vit_b_16(image_size=IMG_SIZE_TCH).to(device)\n",
    "model_tch.heads = torch.nn.Linear(in_features=768, out_features=NUM_CLASSES).to(device)\n",
    "model_tch = torch.compile(model_tch, backend=\"aot_eager\")\n",
    "\n",
    "preds_tch = ClassificationEngine(\n",
    "    model=model_tch,    \n",
    "    device=device).load(\n",
    "        target_dir=MODEL_DIR,\n",
    "        model_name=\"teacher_model.pth\" # Only parameters, not the enginer model\n",
    "    ).predict(\n",
    "        dataloader=test_dataloader, #[image_std, image_tch, class]\n",
    "        output_type=\"argmax\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "matches = preds_std == preds_tch\n",
    "agreement = matches.float().mean().item()\n",
    "print(f\"Student vs Teacher agree on {agreement*100:.1f}% of samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
