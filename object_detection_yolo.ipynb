{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a42571a",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This notebook provides the Python code to create, train, and monitor a deep learning model for object detection. To achieve this, it employs the state-of-the-art You Only Look Once (YOLO) architecture. Compared to R-CNNs (see notebooks `object_detection_rcnn_custom.ipynb` and `object_detection_rcnn_standard.ipynb`), instead of applying the neural network at multiple locations and scales, YOLO processes the entire image with a single network pass, significantly reducing model complexity and inference time.\n",
    "\n",
    "Unlike the other notebooks and use cases in TorchSuite, this one leverages a third-party training framework, [3 Lines of Code (3LC)](https://3lc.ai/), which has been specifically designed for training YOLO models and featuring a comprehensive web-based monitoring interface.\n",
    "\n",
    "This notebook was originally developed by [Duality AI](https://www.duality.ai/) as a template for a Kaggle competition and was later adapted for a specific use case: detecting the presence of humans in images.\n",
    "\n",
    "To use the 3LC framework, please follow the steps described in Section 2.\n",
    "\n",
    "## 1.1. The DeepCount App\n",
    "\n",
    "**TorchSuite** includes a proof-of-concept application called **DeepCount**, which uses the trained YOLO model to detect humans in images. Once the model is trained, it can be tested directly through this app.\n",
    "\n",
    "You can find DeepCount in the subfolder: `demos/deep_count`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfbec9",
   "metadata": {},
   "source": [
    "# 2. 3LC setup\n",
    "See the [3LC Quickstart](https://docs.3lc.ai/3lc/latest/quickstart/quickstart.html) for more details on the sections below.\n",
    "\n",
    "## 2.1. Create a free 3LC account\n",
    "\n",
    "Before getting started, make sure you have a free 3LC account. Go to https://3lc.ai and click \"Sign Up\" in the upper right corner. Sign up for a 3LC account (or log in to an existing one) using your preferred method. Then copy your API Key from the 3LC account home page.\n",
    "\n",
    "## 2.2. Create a Python environment\n",
    "\n",
    "Create a Python environment called \"3LC\" using your preferred tool:\n",
    "- `python -m venv 3LC`\n",
    "  - See the [Python venv documentation](https://docs.python.org/3.12/library/venv.html) for details\n",
    "- `conda create -n 3LC`\n",
    "  - See the [conda documentation](https://docs.conda.io/projects/conda/en/stable/user-guide/getting-started.html) for details, or reach out if you are having trouble\n",
    "\n",
    "## 2.3. Install the 3LC YOLO integration\n",
    "\n",
    "With your \"3LC\" Python environment activated, install the 3LC YOLO integration with the following command. This will also install the `3lc` Python package and all required dependencies.\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/3lc-ai/3lc-ultralytics@develop\n",
    "```\n",
    "And install the Gradio GUI framework:\n",
    "\n",
    "```bash\n",
    "pip install gradio\n",
    "```\n",
    "\n",
    "## 2.4. Configure 3LC with your API key\n",
    "\n",
    "Configure 3LC to use the API key you copied earlier (or get it [here](https://account.3lc.ai/api-key)).\n",
    "\n",
    "```bash\n",
    "3lc login <paste API key here>\n",
    "```\n",
    "\n",
    "## 2.5. Start the 3LC Object Service\n",
    "\n",
    "The [3LC Object Service](https://docs.3lc.ai/3lc/latest/user-guide/object-service/index.html#object-service) is responsible for serving your dataset and metrics to the 3LC Dashboard. It is started from the terminal and can be terminated by pressing Q.\n",
    "\n",
    "```bash\n",
    "3lc service --no-public-examples\n",
    "```\n",
    "\n",
    "## 2.6. Launch the 3LC Dashboard\n",
    "\n",
    "After starting the Object Service, launch the 3LC Dashboard in a browser at https://dashboard.3lc.ai and log in to your 3LC account. Your 3LC project will be displayed in the Dashboard once you begin creating 3LC data below. See the [3LC Dashboard](https://docs.3lc.ai/3lc/latest/user-guide/dashboard/index.html#dashboard-index) documentation for more details.\n",
    "\n",
    "Note that if you want to browse example 3LC projects (in addition to your own), you can start the Object Service in the step above without specifying the `--no-public-examples` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411fb5f",
   "metadata": {},
   "source": [
    "# 2.7. Verify 3LC Setup\n",
    "\n",
    "Now we are almost ready to start creating 3LC `Table`s for your dataset, and `Run`s for your training runs with Ultralytics YOLO.\n",
    "\n",
    "We first import 3LC to verify that the installation and configuration was successful. Make sure you have done the `3lc login` step above to avoid prompts or errors related to specifying a 3LC API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0dc8a",
   "metadata": {},
   "source": [
    "# 3. Downloading the Dataset\n",
    "\n",
    "Download the People Detection dataset from the following link, selecting the **YOLOv8** annotations:\n",
    "\n",
    "ðŸ”— https://universe.roboflow.com/leo-ueno/people-detection-o4rdr/dataset/10\n",
    "\n",
    "After downloading, update the `yolo_params.yml` file to include the paths to the training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0296a59",
   "metadata": {},
   "source": [
    "# 4. Creating 3LC Tables\n",
    "\n",
    "Run the following code to create 3LC Tables for the dataset. Before that, modify the paths for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def scan_labels(labels_dir, images_dir, bad_dir):\n",
    "\n",
    "    \"\"\"\n",
    "    Scans YOLO label files in `labels_dir` for invalid entries.\n",
    "    Moves invalid label files and corresponding images to `bad_dir`.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(bad_dir, exist_ok=True)\n",
    "\n",
    "    def is_label_file_valid(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line_num, line in enumerate(f, start=1):\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    print(f\"[EMPTY] {file_path} (line {line_num})\")\n",
    "                    return False\n",
    "                if len(parts) != 5:\n",
    "                    print(f\"[BAD] {file_path} (line {line_num} has {len(parts)} values)\")\n",
    "                    return False\n",
    "                try:\n",
    "                    int(parts[0])\n",
    "                    [float(x) for x in parts[1:]]\n",
    "                except ValueError:\n",
    "                    print(f\"[INVALID VALUE] {file_path} (line {line_num})\")\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    # Scan all label files\n",
    "    for file in os.listdir(labels_dir):\n",
    "        if not file.endswith(\".txt\"):\n",
    "            continue\n",
    "        label_path = os.path.join(labels_dir, file)\n",
    "        image_name = os.path.splitext(file)[0] + \".jpg\"\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "\n",
    "        if not is_label_file_valid(label_path):\n",
    "            print(f\"Moving bad label and image: {file}\")\n",
    "            shutil.move(label_path, os.path.join(bad_dir, file))\n",
    "            if os.path.exists(image_path):\n",
    "                shutil.move(image_path, os.path.join(bad_dir, image_name))\n",
    "            else:\n",
    "                print(f\"[MISSING IMAGE] {image_name}\")\n",
    "\n",
    "    print(\"âœ… Scan complete. Bad files moved to:\", bad_dir)\n",
    "\n",
    "\n",
    "# Paths for training set\n",
    "labels_dir = r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\train\\labels\" # Change the path\n",
    "images_dir = r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\train\\images\" # Change the path\n",
    "bad_dir = os.path.join(r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\train\", \"train_bad\") # Change the path\n",
    "scan_labels(labels_dir, images_dir, bad_dir)\n",
    "\n",
    "# Paths for validation set\n",
    "labels_dir = r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\valid\\labels\" # Change the path \n",
    "images_dir = r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\valid\\images\" # Change the path\n",
    "bad_dir = os.path.join(r\"D:\\Repos\\coco_dataset\\People Detection.v10-rf-detr-nano.yolov8\\valid\", \"valid_bad\") # Change the path\n",
    "scan_labels(labels_dir, images_dir, bad_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "PROJECT_NAME = \"DeepCount\"  # Place all 3LC Tables and Runs in the same project\n",
    "\n",
    "# This for loop allows you to create multiple 3LC Tables (e.g., train and val sets) in one go\n",
    "for split in [\"train\", \"val\"]:\n",
    "    table = tlc.Table.from_yolo(\n",
    "        dataset_yaml_file=\"yolo_params.yaml\",  # the yolo_params.yaml file in the data folder you generate from Falcon\n",
    "        split=split,\n",
    "        table_name=\"initial\",\n",
    "        dataset_name=split,\n",
    "        project_name=PROJECT_NAME,\n",
    "    )\n",
    "\n",
    "    print(f\"Created table with URL: {table.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff6a97",
   "metadata": {},
   "source": [
    "# 5. Training a YOLO model\n",
    "\n",
    "The following code trains a YOLO model with the 3LC YOLO integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde97b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be16c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc_ultralytics import Settings, YOLO\n",
    "import tlc\n",
    "\n",
    "# Load YOLOv10-balanced\n",
    "yolo_version = '10b'\n",
    "RUN_NAME = f\"run-{yolo_version}\"  # Define the run name to organize all your runs in a nice way\n",
    "\n",
    "# Set 3LC specific settings\n",
    "settings = Settings(\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    run_description=f\"yolo {yolo_version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the URLs for the train and val tables when you make data revisions in 3LC Dashboard\n",
    "train_table = tlc.Table.from_url(\"C:/Users/ssre_/AppData/Local/3LC/3LC/projects/DeepCount/datasets/train/tables/initial\") # Change the path \n",
    "val_table = tlc.Table.from_url(\"C:/Users/ssre_/AppData/Local/3LC/3LC/projects/DeepCount/datasets/val/tables/initial\") # Change the path\n",
    "\n",
    "model = YOLO(F\"yolov{yolo_version}.pt\")\n",
    "\n",
    "# Training configuration\n",
    "model.train(\n",
    "    tables={\"train\": train_table, \"val\": val_table},\n",
    "    settings=settings,         # your hyperparameter settings dict\n",
    "    imgsz=640,                 # scale shorter side to 640px (matches typical YOLO training)\n",
    "    epochs=50,                 # enough to converge on 15k images\n",
    "    batch=8,                   # you can adjust based on memory; effective batch = batch * accum_steps\n",
    "    nbs=16,                    # nominal batch size for auto-scaling\n",
    "    project=PROJECT_NAME,\n",
    "    name=RUN_NAME,\n",
    "    workers=1,                 # adjust to your CPU cores\n",
    "    resume=False,              # continue training if checkpoint exists\n",
    "\n",
    "    # Optimizer and learning rate\n",
    "    optimizer=\"auto\",          # default YOLO choice\n",
    "    lr0=0.001,                 # slightly lower than default 0.01 for stability\n",
    "    lrf=0.01,                  # final LR fraction (default)\n",
    "    cos_lr=True,\n",
    "    momentum=0.937,            # default for SGD\n",
    "    weight_decay=0.0005,       # default\n",
    "\n",
    "    # Warmup settings\n",
    "    warmup_epochs=3,           # default\n",
    "    warmup_bias_lr=0.1 * 0.006,\n",
    "    warmup_momentum=0.8,       # default\n",
    "\n",
    "    # Data augmentation (minimal since dataset already augmented)\n",
    "    augment=False,\n",
    "    mosaic=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    degrees=10,\n",
    "    translate=0.005,\n",
    "    scale=0.0,\n",
    "    perspective=0.0,\n",
    "    cutmix=0.0,\n",
    "\n",
    "    # Training control\n",
    "    patience=100,        # early stopping patience\n",
    "    agnostic_nms=True,   # class-agnostic NMS\n",
    "    visualize=True,      # visualize during training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a08567",
   "metadata": {},
   "source": [
    "# 6. The DeepCount App\n",
    "\n",
    "Once the model has been trained, move the exported model file to the following folder:\n",
    "\n",
    "`demos/deep_count`\n",
    "\n",
    "Next, navigate to that directory in your terminal and run the application using the following command:\n",
    "\n",
    "```bash\n",
    "python app.py --model <model_name>\n",
    "```\n",
    "\n",
    "This will launch the DeepCount app, allowing you to test the trained YOLO model on sample images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3LC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
