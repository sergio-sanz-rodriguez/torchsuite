{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e3e0ca",
   "metadata": {},
   "source": [
    "# 1. Introuction\n",
    "\n",
    " This notebook outlines the creation, compilation, and training of a Swin Tranformer network to classify 101 types of food. To this end, the **distillation technique** is applied to learn from a larger, pre-trained transformer model, especifically, a ViT-Base/16-384 transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555499",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ConstantLR, SequentialLR, CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom libraries\n",
    "from utils.classification_utils import display_random_images_classification\n",
    "from utils.common_utils import set_seeds\n",
    "from engines.classification import ClassificationEngine, Common\n",
    "from engines.loss_functions import DistillationLossForDeiT\n",
    "from dataloaders.image_dataloaders import create_distillation_dataloaders, create_classification_dataloaders\n",
    "from models.pretrained_models import build_pretrained_model\n",
    "from models.deit import DeiT\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.autograd.graph\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"onnxscript.converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403c078",
   "metadata": {},
   "source": [
    "# 3. Importing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f231dc9",
   "metadata": {},
   "source": [
    "The dataset should be organized as follows, with one subdirectory per class containing the corresponding images:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── train/\n",
    "│   └── <class_label>/\n",
    "│       ├── img1.jpg\n",
    "│       ├── img2.png\n",
    "│       └── ...\n",
    "└── test/ (or val/)/\n",
    "    └── <class_label>/\n",
    "        ├── img1.jpg\n",
    "        ├── img2.png\n",
    "        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94336973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "AMOUNT_TO_GET = 1.0\n",
    "SEED = 42\n",
    "THEME = 'light' # or 'dark'. Default is 'light'\n",
    "\n",
    "# Define target data directory\n",
    "TARGET_DIR_NAME = f\"data/food-101_{str(int(AMOUNT_TO_GET*100))}_percent\"\n",
    "\n",
    "# Setup training and test directories\n",
    "TARGET_DIR = Path(TARGET_DIR_NAME)\n",
    "TRAIN_DIR = TARGET_DIR / \"train\"\n",
    "TEST_DIR = TARGET_DIR / \"test\"\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target model directory\n",
    "MODEL_DIR = Path(\"outputs\")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "IMPORT_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18615cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPORT_DATASET:\n",
    "    # Download dataset from Hugging Face\n",
    "    ds = load_dataset(\"ethz/food101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc78c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPORT_DATASET:\n",
    "    # Get class names\n",
    "    class_names = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "    # Function to save images into appropriate directories\n",
    "    def save_images(split, target_dir):\n",
    "        for example in tqdm(ds[split], desc=f\"Saving {split} images\"):\n",
    "            image = example[\"image\"]\n",
    "            label = example[\"label\"]\n",
    "            class_name = class_names[label]\n",
    "\n",
    "            # Define class directory\n",
    "            class_dir = target_dir / class_name\n",
    "            class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Save image\n",
    "            img_path = class_dir / f\"{len(list(class_dir.iterdir()))}.jpg\"\n",
    "            image.save(img_path)\n",
    "\n",
    "    # Save training and test images\n",
    "    save_images(\"train\", TRAIN_DIR)\n",
    "    save_images(\"validation\", TEST_DIR)\n",
    "\n",
    "    print(\"Dataset has been saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279df5f",
   "metadata": {},
   "source": [
    "# 4. Specifying Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate cuda benchmark\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "#if device == \"cuda\":\n",
    "#    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350701ec-c5f9-4809-884c-69a5dcf97ceb",
   "metadata": {},
   "source": [
    "# 5. Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "manual_transforms = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.RandomCrop((256, 256)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=manual_transforms)\n",
    "display_random_images_classification(\n",
    "    train_data,\n",
    "    n=25,\n",
    "    classes=train_data.classes,\n",
    "    rows=5,\n",
    "    cols=5,\n",
    "    display_shape=False,\n",
    "    seed=None,\n",
    "    theme=THEME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c28c3",
   "metadata": {},
   "source": [
    "# 6. Creating Teacher and Student - 101 Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae602ca0",
   "metadata": {},
   "source": [
    "To download a teacher model example, click [here](https://drive.google.com/file/d/1uHQ9WotGHh6suSMvkyO0vLj1O8XlJ_yE/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transformations\n",
    "IMG_SIZE_TCH = 384\n",
    "IMG_SIZE_STD = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "transform_train_tch = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((IMG_SIZE_TCH)), # According to the PyTorch documentation\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_tch = v2.Compose([    \n",
    "    v2.Resize((IMG_SIZE_TCH)), # According to the PyTorch documentation\n",
    "    v2.CenterCrop((IMG_SIZE_TCH, IMG_SIZE_TCH)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_train_std = v2.Compose([    \n",
    "    v2.TrivialAugmentWide(),\n",
    "    v2.Resize((256)), # According to the PyTorch documentation\n",
    "    v2.RandomCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_test_std = v2.Compose([    \n",
    "    v2.Resize((256)), # According to the PyTorch documentation\n",
    "    v2.CenterCrop((IMG_SIZE_STD, IMG_SIZE_STD)),    \n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = create_distillation_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    transform_student_train=transform_train_std,\n",
    "    transform_teacher_train=transform_train_tch,\n",
    "    transform_student_test=transform_test_std,\n",
    "    transform_teacher_test=transform_test_tch,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'test':  test_dataloader\n",
    "}\n",
    "\n",
    "# Compute number of classees\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "# Load the teacher model: ViT-Base/16-384 \n",
    "model_tch_type=\"teacher_model\"\n",
    "model_tch_name = model_tch_type + \".pth\"\n",
    "model_tch = build_pretrained_model(\n",
    "    model=\"vit_b_16_384\",\n",
    "    output_dim=NUM_CLASSES,\n",
    "    seed=SEED,\n",
    "    freeze_backbone=False,\n",
    "    device=device\n",
    "    )\n",
    "model_tch = torch.compile(model_tch, backend=\"aot_eager\") # Compilation needed as the teacher model was trained with torch.compile\n",
    "\n",
    "# Load the trained weights\n",
    "model_tch = Common().load_model(\n",
    "    model=model_tch,\n",
    "    target_dir=MODEL_DIR,\n",
    "    model_name=model_tch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc544d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the student model\n",
    "model_std = DeiT(\n",
    "    img_size=IMG_SIZE_STD,\n",
    "    in_channels=3,\n",
    "    patch_size=16,\n",
    "    num_transformer_layers=12,\n",
    "    emb_dim=192,\n",
    "    mlp_size=768,\n",
    "    num_heads=3,\n",
    "    attn_dropout=0,\n",
    "    mlp_dropout=0.1,\n",
    "    emb_dropout=0.05,\n",
    "    drop_path_rate=0.1,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Print model_tch summary\n",
    "display(summary(model_tch,\n",
    "        input_size=(BATCH_SIZE,3,IMG_SIZE_TCH, IMG_SIZE_TCH),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]))\n",
    "\n",
    "# Print model_std summary\n",
    "display(summary(model_std,\n",
    "        input_size=(BATCH_SIZE,3,IMG_SIZE_STD, IMG_SIZE_STD),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f72f2f",
   "metadata": {},
   "source": [
    "# 7. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_std_type=\"student_deit\"\n",
    "model_std_name = model_std_type + \".pth\"\n",
    "\n",
    "# Epochs and learning rate\n",
    "EPOCHS = 100\n",
    "LR = 3e-4\n",
    "MIN_LR = 1e-6\n",
    "WARMUP_EPOCHS = 5\n",
    "ALPHA_MAX = 0.7\n",
    "ALPHA_RAMP_EPOCHS = 10\n",
    "T = 4.0\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model_std.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.05\n",
    ")\n",
    "\n",
    "# Create loss function with dynamic alpha\n",
    "# Alpha schedule list (length = EPOCHS)\n",
    "alpha_schedule = [\n",
    "    1.0 - (1.0 - ALPHA_MAX) * min(1.0, e / ALPHA_RAMP_EPOCHS)  # linear 1.0 -> 0.7\n",
    "    for e in range(EPOCHS)\n",
    "]\n",
    "\n",
    "# This loss function receives five arguments:\n",
    "# 1. Student's classification [CLS] output\n",
    "# 2. Student's distillations [DST] output\n",
    "# 3. Teacher's classificaiton output\n",
    "# 4. Ground-truth\n",
    "# 5. Actual epoch for epoch-base alpha schedule; for constant alpha over epochs, it is just a float\n",
    "loss_fn = DistillationLossForDeiT(alpha=alpha_schedule, temperature=T, label_smoothing=0.1)\n",
    "\n",
    "# Initialize the scheduler\n",
    "warmup = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=1e-3, total_iters=WARMUP_EPOCHS\n",
    ")\n",
    "cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=MIN_LR\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup, cosine], milestones=[WARMUP_EPOCHS]\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the engine\n",
    "engine = ClassificationEngine(\n",
    "    model=model_std,                                # Model to be trained\n",
    "    model_teacher=model_tch,                        # Teacher model if knowledge distillation training is enabled (use_distillation=True)\n",
    "    use_distillation=True,                          # Whether training uses knowledge distillation, then model_teacher is required    \n",
    "    optimizer=optimizer,                            # Optimizer\n",
    "    loss_fn=loss_fn,                                # Loss function\n",
    "    scheduler=scheduler,                            # Scheduler\n",
    "    theme=THEME,                                    # Theme\n",
    "    device=device                                   # Target device\n",
    "    )\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                           # Directory where the model will be saved\n",
    "    model_name=model_std_name,                      # Name of the student model    \n",
    "    enable_resume=True,                             # Resume training from the last saved checkpoint\n",
    "    dataloaders=dataloaders,                        # Dictionary with the dataloaders\n",
    "    save_best_model=[\"last\", \"loss\", \"acc\", \"f1\"],  # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,               # If False: do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    apply_validation=True,                          # Enable validation step\n",
    "    augmentation_strategy=\"always\",                 # Augmentation strategy\n",
    "    recall_threshold=0.995,                         # False   positive rate at recall_threshold recall\n",
    "    recall_threshold_pauc=0.95,                     # Partial AUC score above recall_threshold_pauc recall\n",
    "    epochs=EPOCHS,                                  # Total number of epochs\n",
    "    amp=True,                                       # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                          # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                               # Disable debug mode    \n",
    "    accumulation_steps=4,                           # Accumulation steps 4: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2029d93",
   "metadata": {},
   "source": [
    "## 7.1. (Optional) Retraining the Last Best-performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae55b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the student model\n",
    "model_std = DeiT(\n",
    "    img_size=IMG_SIZE_STD,\n",
    "    in_channels=3,\n",
    "    patch_size=16,\n",
    "    num_transformer_layers=12,\n",
    "    emb_dim=192,\n",
    "    mlp_size=768,\n",
    "    num_heads=3,\n",
    "    attn_dropout=0,\n",
    "    mlp_dropout=0.1,\n",
    "    emb_dropout=0.05,\n",
    "    drop_path_rate=0.1,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Load the trained weights for the student model\n",
    "import glob\n",
    "import re\n",
    "model_paths = glob.glob(os.path.join(MODEL_DIR, \"student_deit_acc_epoch*.pth\"))\n",
    "assert len(model_paths) > 0, \"No matching model files found\"\n",
    "def extract_epoch(path):\n",
    "    fname = os.path.basename(path)\n",
    "    match = re.search(r\"epoch(\\d+)\", fname)\n",
    "    if match is None:\n",
    "        raise ValueError(f\"Could not parse epoch from {fname}\")\n",
    "    return int(match.group(1))\n",
    "\n",
    "best_path = max(model_paths, key=extract_epoch)\n",
    "model_name = os.path.basename(best_path)\n",
    "\n",
    "model_std = Common().load_model(\n",
    "    model=model_std,\n",
    "    target_dir=MODEL_DIR,\n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_std_type=\"student_deit_pretrained\"\n",
    "model_std_name = model_std_type + \".pth\"\n",
    "\n",
    "# Epochs and learning rate\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "MIN_LR = 1e-6\n",
    "WARMUP_EPOCHS = 2\n",
    "WARMUP_START_FACTOR = 0.1\n",
    "ALPHA_MAX = 0.7\n",
    "ALPHA_RAMP_EPOCHS = 10\n",
    "T = 4.0\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model_std.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.05\n",
    ")\n",
    "\n",
    "# Create loss function with dynamic alpha\n",
    "# Alpha schedule list (length = EPOCHS)\n",
    "alpha_schedule = [\n",
    "    1.0 - (1.0 - ALPHA_MAX) * min(1.0, e / ALPHA_RAMP_EPOCHS)\n",
    "    for e in range(EPOCHS)\n",
    "]\n",
    "\n",
    "# This loss function receives five arguments:\n",
    "# 1. Student's classification [CLS] output\n",
    "# 2. Student's distillations [DST] output\n",
    "# 3. Teacher's classificaiton output\n",
    "# 4. Ground-truth\n",
    "# 5. Actual epoch for epoch-base alpha schedule; for constant alpha over epochs, it is just a float\n",
    "loss_fn = DistillationLossForDeiT(alpha=alpha_schedule, temperature=T, label_smoothing=0.1)\n",
    "\n",
    "# Initialize the scheduler\n",
    "warmup = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=WARMUP_START_FACTOR, total_iters=WARMUP_EPOCHS\n",
    ")\n",
    "cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=MIN_LR\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup, cosine], milestones=[WARMUP_EPOCHS]\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the engine\n",
    "engine = ClassificationEngine(\n",
    "    model=model_std,                                # Model to be trained\n",
    "    model_teacher=model_tch,                        # Teacher model if knowledge distillation training is enabled (use_distillation=True)\n",
    "    use_distillation=True,                          # Whether training uses knowledge distillation, then model_teacher is required    \n",
    "    optimizer=optimizer,                            # Optimizer\n",
    "    loss_fn=loss_fn,                                # Loss function\n",
    "    scheduler=scheduler,                            # Scheduler\n",
    "    theme=THEME,                                    # Theme\n",
    "    device=device                                   # Target device\n",
    "    )\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                           # Directory where the model will be saved\n",
    "    model_name=model_std_name,                      # Name of the student model    \n",
    "    enable_resume=True,                             # Resume training from the last saved checkpoint\n",
    "    dataloaders=dataloaders,                        # Dictionary with the dataloaders\n",
    "    save_best_model=[\"last\", \"loss\", \"acc\", \"f1\"],  # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,               # If False: do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    apply_validation=True,                          # Enable validation step\n",
    "    augmentation_strategy=\"always\",                 # Augmentation strategy\n",
    "    recall_threshold=0.995,                         # False   positive rate at recall_threshold recall\n",
    "    recall_threshold_pauc=0.95,                     # Partial AUC score above recall_threshold_pauc recall\n",
    "    epochs=EPOCHS,                                  # Total number of epochs\n",
    "    amp=True,                                       # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                          # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                               # Disable debug mode    \n",
    "    accumulation_steps=4,                           # Accumulation steps 4: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910ae33",
   "metadata": {},
   "source": [
    "# 8. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for the teacher\n",
    "_, test_dataloader, _ = create_classification_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    train_transform=transform_train_tch,\n",
    "    test_transform=transform_test_tch,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Make predictions with the student\n",
    "preds_tch = ClassificationEngine(\n",
    "    model= torch.compile(build_pretrained_model(\n",
    "        model=\"vit_b_16_384\",\n",
    "        output_dim=NUM_CLASSES,\n",
    "        seed=SEED,\n",
    "        freeze_backbone=False,\n",
    "        device=device\n",
    "        ), backend=\"aot_eager\"),\n",
    "    device=device).load(\n",
    "        target_dir=MODEL_DIR,\n",
    "        model_name=\"teacher_model.pth\" # Only parameters, not the enginer model\n",
    "    ).predict(\n",
    "        dataloader=test_dataloader, #[image_std, image_tch, class]\n",
    "        output_type=\"argmax\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9dc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for the student\n",
    "_, test_dataloader, _ = create_classification_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    train_transform=transform_train_std,\n",
    "    test_transform=transform_test_std,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Make predictions with the student\n",
    "preds_std = ClassificationEngine(\n",
    "    model=build_pretrained_model(\n",
    "        model=\"swin_v2_t\",\n",
    "        output_dim=NUM_CLASSES,\n",
    "        seed=SEED,\n",
    "        freeze_backbone=False,\n",
    "        device=device\n",
    "        ),\n",
    "    device=device\n",
    "    ).load(\n",
    "        target_dir=MODEL_DIR,\n",
    "        model_name=\"student_model.pth\" # Only parameters, not the engine model. Modify the file name if necessary.\n",
    "    ).predict(\n",
    "        dataloader=test_dataloader,\n",
    "        output_type=\"argmax\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "matches = preds_std == preds_tch\n",
    "agreement = matches.float().mean().item()\n",
    "print(f\"Student vs Teacher agree on {agreement*100:.1f}% of samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
